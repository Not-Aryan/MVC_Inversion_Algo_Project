{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute tractions using the results from the Greenland traction inversion: \n",
    "## <font color=blue>\"compute_predicted_strain_rates.ipynb\"</font>\n",
    "#### Jul 25, 2022  <font color=red>(v. testing)</font>\n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "\n",
    "1. A G-matrix will be built using \"strain\" basis functions. \n",
    "2. And then the model coefficients will be multiplied to the G-matrix to obtain **${e}_{ij}^{obs}$**.\n",
    "3. Using the **${e}_{ij}^{obs}$** and the equations in Finzel et al. (2015, GRL), this code computes sigma xx, sigma xy, tau_0. #greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversion_results = sys.argv[1]\n",
    "# inversion_results = str(inversion_results)\n",
    "\n",
    "#model_coef_Ridge_0.16876124757881522.out\n",
    "#model_coef_Ridge_0.1519911082952933.out\n",
    "\n",
    "inversion_results = \"./inver_results_cm\\model_coef_Ridge_0.1519911082952933_1.0.out\"\n",
    "# inversion_results = \"./Inversion_results_new_magnitudes\\model_coef_Ridge_0.1519911082952933__1.0.out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_coefs = np.loadtxt(inversion_results)\n",
    "\n",
    "######## How Many Basis Functions \n",
    "HowManyBasisFunctions=np.loadtxt(\"geometry_info.txt\", skiprows=1)\n",
    "HowManyCell=int(HowManyBasisFunctions[1])\n",
    "# HowManyCell = 172\n",
    "\n",
    "# Output files\n",
    "exx_pred = \"exx_pred.xyz\"\n",
    "eyy_pred = \"eyy_pred.xyz\"\n",
    "exy_pred = \"exy_pred.xyz\"\n",
    "\n",
    "pred1 = \"sig_xx_pred.xyz\"\n",
    "pred2 = \"tau_0_pred.xyz\"\n",
    "pred3 = \"sig_xy_cosy_cosy_pred.xyz\"\n",
    "pred4 = \"sig_xy_pred.xyz\"\n",
    "pred5 = \"sig_xx_cosy_cosy_pred.xyz\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `STEP 1:` **BUILD G-Matrix (strain rates), $\\bar{\\bar{G}}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample = \"./FILES_basis_functions/average_strain_RECTANGULAR_1_1.out\"\n",
    "sample = np.loadtxt(input_sample)\n",
    "data_length=len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon=sample[:,2]\n",
    "lat=sample[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421</td>\n",
       "      <td>422</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>422</td>\n",
       "      <td>423</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423</td>\n",
       "      <td>424</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>-0.000865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460</td>\n",
       "      <td>461</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>461</td>\n",
       "      <td>462</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>868</td>\n",
       "      <td>869</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>869</td>\n",
       "      <td>870</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>870</td>\n",
       "      <td>871</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>871</td>\n",
       "      <td>872</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>872</td>\n",
       "      <td>873</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    0     1     2         3         4         5    6    7    8\n",
       "0           421  422  61.0 -47.0 -0.001589  0.000400 -0.001146  0.0  0.0  0.0\n",
       "1           422  423  61.0 -45.0 -0.001613  0.000454 -0.001000  0.0  0.0  0.0\n",
       "2           423  424  61.0 -43.0 -0.001620  0.000488 -0.000865  0.0  0.0  0.0\n",
       "3           460  461  63.0 -49.0 -0.001231  0.000066 -0.001365  0.0  0.0  0.0\n",
       "4           461  462  63.0 -47.0 -0.001318  0.000174 -0.001239  0.0  0.0  0.0\n",
       "..          ...  ...   ...   ...       ...       ...       ...  ...  ...  ...\n",
       "167         868  869  83.0 -33.0 -0.000212 -0.000334 -0.000305  0.0  0.0  0.0\n",
       "168         869  870  83.0 -31.0 -0.000241 -0.000307 -0.000320  0.0  0.0  0.0\n",
       "169         870  871  83.0 -29.0 -0.000270 -0.000279 -0.000332  0.0  0.0  0.0\n",
       "170         871  872  83.0 -27.0 -0.000300 -0.000250 -0.000342  0.0  0.0  0.0\n",
       "171         872  873  83.0 -25.0 -0.000330 -0.000221 -0.000350  0.0  0.0  0.0\n",
       "\n",
       "[172 rows x 10 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midpoints_on_greenland = pd.read_csv(\"midpoints_on_greenland.csv\")\n",
    "midpoints_on_greenland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G_exx_resp = pd.DataFrame(index = range(data_length))\n",
    "df_G_eyy_resp = pd.DataFrame(index = range(data_length)) \n",
    "df_G_exy_resp = pd.DataFrame(index = range(data_length)) \n",
    "\n",
    "names = ['cell_num','lat','lon','exx_resp','eyy_resp','exy_resp','std_exx_resp','std_eyy_resp','std_exy_resp']\n",
    "# Make a blank G matrix part related to Boundary Condition on data points\n",
    "\n",
    "for i in range(1,HowManyCell+1):\n",
    "    \n",
    "    inputfile_exx = \"./FILES_basis_functions/average_strain_RECTANGULAR_\"+str(i)+\"_1\"+\".out\" \n",
    "    #exx responses\n",
    "    inputfile_eyy = \"./FILES_basis_functions/average_strain_RECTANGULAR_\"+str(i)+\"_2\"+\".out\" \n",
    "    #eyy responses\n",
    "    inputfile_exy = \"./FILES_basis_functions/average_strain_RECTANGULAR_\"+str(i)+\"_3\"+\".out\" \n",
    "    #exy responses \n",
    "\n",
    "\n",
    "    df_exx=pd.read_csv(inputfile_exx, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_eyy=pd.read_csv(inputfile_eyy, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')\n",
    "    df_exy=pd.read_csv(inputfile_exy, header=None, sep=r'(?:,|\\s+)', \n",
    "                           comment='#', engine='python')   \n",
    "\n",
    "# CHANGE the column names \n",
    "\n",
    "    df_exx.columns = names\n",
    "    df_eyy.columns = names\n",
    "    df_exy.columns = names\n",
    "       \n",
    "    df_G_exx_resp[\"G_exx_resp_from_exx_\"+str(i)] = df_exx.loc[:,['exx_resp']]\n",
    "    df_G_exx_resp[\"G_exx_resp_from_eyy_\"+str(i)] = df_eyy.loc[:,['exx_resp']]\n",
    "    df_G_exx_resp[\"G_exx_resp_from_exy_\"+str(i)] = df_exy.loc[:,['exx_resp']]\n",
    "    \n",
    "    df_G_eyy_resp[\"G_eyy_resp_from_exx_\"+str(i)] = df_exx.loc[:,['eyy_resp']]\n",
    "    df_G_eyy_resp[\"G_eyy_resp_from_eyy_\"+str(i)] = df_eyy.loc[:,['eyy_resp']]\n",
    "    df_G_eyy_resp[\"G_eyy_resp_from_exy_\"+str(i)] = df_exy.loc[:,['eyy_resp']]\n",
    "    \n",
    "    df_G_exy_resp[\"G_exy_resp_from_exx_\"+str(i)] = df_exx.loc[:,['exy_resp']]\n",
    "    df_G_exy_resp[\"G_exy_resp_from_eyy_\"+str(i)] = df_eyy.loc[:,['exy_resp']]\n",
    "    df_G_exy_resp[\"G_exy_resp_from_exy_\"+str(i)] = df_exy.loc[:,['exy_resp']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "1000\n",
      "(1000, 3000)\n",
      "(1000, 3000)\n",
      "(1000, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(np_model_coefs.shape)\n",
    "print(HowManyCell)\n",
    "print(df_G_exy_resp.shape)\n",
    "print(df_G_eyy_resp.shape)\n",
    "print(df_G_exy_resp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> These are strain rate basis functions ! </b>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b> strain rate basis functions @ model coefficients = predicted strain </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### df G to np G\n",
    "np_G_exx_resp=df_G_exx_resp.to_numpy()\n",
    "np_G_eyy_resp=df_G_eyy_resp.to_numpy()\n",
    "np_G_exy_resp=df_G_exy_resp.to_numpy()\n",
    "\n",
    "### G*m (prediction for strain)\n",
    "\n",
    "#when you perturb your model coefficents, obtain the predicted velocity using the new coefficents and run this code to obtain the new strain responses\n",
    "#that corespond to the new model vectors\n",
    "#these new strain responses can be used to compute the basal tractions to see how they change\n",
    "#plot the new velocity field on the surface\n",
    "#when you reduce the model coefficents, you want to take model prediction add to GPE velocity to get InSAR velocity\n",
    "\n",
    "np_exx_pred = np_G_exx_resp @ np_model_coefs\n",
    "np_eyy_pred = np_G_eyy_resp @ np_model_coefs\n",
    "np_exy_pred = np_G_exy_resp @ np_model_coefs\n",
    "\n",
    "np_sig_xy = np_exy_pred #strain rate responses to corresponding to basis functions\n",
    "np_sig_xx = 1/2*(np_exx_pred - np_eyy_pred)\n",
    "np_tau_0 = 3/2*(np_exx_pred + np_eyy_pred)\n",
    "\n",
    "\n",
    "np_sig_xy_cosycosy = np_sig_xy*(np.cos(lat*np.pi/180)**2)\n",
    "np_sig_xx_cosycosy = np_sig_xx*(np.cos(lat*np.pi/180)**2)\n",
    "\n",
    "### dictionary for  xyz files\n",
    "dict_exx_pred = {'lon': lon, 'lat': lat, 'exx': np_exx_pred}\n",
    "dict_eyy_pred = {'lon': lon, 'lat': lat, 'eyy': np_eyy_pred}\n",
    "dict_exy_pred = {'lon': lon, 'lat': lat, 'exy': np_exy_pred}\n",
    "\n",
    "\n",
    "dict_sig_xx_pred = {'lon': lon, 'lat': lat, 'sigxx': np_sig_xx}\n",
    "dict_tau_0_pred = {'lon': lon, 'lat': lat, 'tau0': np_tau_0}\n",
    "dict_sig_xy_cosycosy_pred = {'lon': lon, 'lat': lat, 'sigxy_cosy_cosy': np_sig_xy_cosycosy}\n",
    "dict_sig_xy_pred = {'lon': lon, 'lat': lat, 'sigxy': np_sig_xy}\n",
    "dict_sig_xx_cosycosy_pred = {'lon': lon, 'lat': lat, 'sigxx_cosy_cosy': np_sig_xx_cosycosy}\n",
    "\n",
    "\n",
    "### dict to df \n",
    "df_exx_pred = pd.DataFrame(dict_exx_pred)\n",
    "df_eyy_pred = pd.DataFrame(dict_eyy_pred)\n",
    "df_exy_pred = pd.DataFrame(dict_exy_pred)\n",
    "\n",
    "\n",
    "df_sig_xx_pred = pd.DataFrame(dict_sig_xx_pred)\n",
    "df_tau_0_pred = pd.DataFrame(dict_tau_0_pred)\n",
    "df_sig_xy_cosycosy_pred = pd.DataFrame(dict_sig_xy_cosycosy_pred)\n",
    "df_sig_xy_pred = pd.DataFrame(dict_sig_xy_pred)\n",
    "df_sig_xx_cosycosy_pred = pd.DataFrame(dict_sig_xx_cosycosy_pred)\n",
    "\n",
    "\n",
    "\n",
    "### save df\n",
    "\n",
    "df_exx_pred.to_csv(exx_pred,header=None, index=None, sep=' ')\n",
    "df_eyy_pred.to_csv(eyy_pred,header=None, index=None, sep=' ')\n",
    "df_exy_pred.to_csv(exy_pred,header=None, index=None, sep=' ')\n",
    "\n",
    "\n",
    "df_sig_xx_pred.to_csv(pred1,header=None, index=None, sep=' ')\n",
    "df_tau_0_pred.to_csv(pred2,header=None, index=None, sep=' ')\n",
    "df_sig_xy_cosycosy_pred.to_csv(pred3,header=None, index=None, sep=' ')\n",
    "df_sig_xy_pred.to_csv(pred4,header=None, index=None, sep=' ')\n",
    "df_sig_xx_cosycosy_pred.to_csv(pred5,header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pygmt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f18ea9b510a311e54183553013794b864ebc712ddd78fbd1b6a1b84d0d294a58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
